{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2910b064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "50231    1\n",
       "50232    1\n",
       "50233    1\n",
       "50234    1\n",
       "50235    1\n",
       "Name: label, Length: 50236, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying out SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as PipelineSmote\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('C:/Users/sarpk/Desktop/TUe courses/Language&AI/assignment/cleaned_extrovert.csv', engine='pyarrow')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['post'], df['label'], test_size=0.2, random_state=5)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000)  # Adjust the number of features to suit your dataset\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "#reduce dimensionality for more efficient use in SMOTE\n",
    "svd = TruncatedSVD(n_components=100) \n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "\n",
    "# Now apply SMOTE to generate synthetic samples in this reduced feature space\n",
    "smote = SMOTE(random_state=5)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_svd, y_train)\n",
    "\n",
    "y_resampled_list = []\n",
    "for label in y_resampled:\n",
    "    y_resampled_list.append(label)\n",
    "    \n",
    "#50236 rows vs 40k in original dataset, there's exactly same amount of labels (25118 label 0 and 25118 label 1)\n",
    "#not sure if this is the best method to do it.\n",
    "#in general I don't think SMOTE is the best way to deal with the imbalanced dataset problem. when I was researching I also\n",
    "#saw places which said SMOTE isn't that good when used in oversampling text data, therefore I'm going to try the method used in \n",
    "#the lab session.\n",
    "\n",
    "y_resampled\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bebf4034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      6252\n",
      "           1       0.62      0.47      0.53      1839\n",
      "\n",
      "    accuracy                           0.81      8091\n",
      "   macro avg       0.74      0.69      0.71      8091\n",
      "weighted avg       0.80      0.81      0.80      8091\n"
     ]
    }
   ],
   "source": [
    "#from pycharm in Ata testing\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "pipeline_smote = PipelineSmote([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('smote', SMOTE(random_state=5)),\n",
    "    ('classifier', ComplementNB())\n",
    "])\n",
    "\n",
    "pipeline_smote.fit(X_train, y_train)\n",
    "\n",
    "##%%\n",
    "y_pred = pipeline_smote.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1341e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method used in the lecture for imbalanced dataset problem\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('C:/Users/sarpk/Desktop/TUe courses/Language&AI/assignment/cleaned_extrovert.csv', engine='pyarrow')\n",
    "X = df['post']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=5, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "307b5a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report without stratification:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3140\n",
      "           1       0.91      0.07      0.13       906\n",
      "\n",
      "    accuracy                           0.79      4046\n",
      "   macro avg       0.85      0.53      0.51      4046\n",
      "weighted avg       0.82      0.79      0.71      4046\n",
      "\n",
      "Classification report with stratification:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3138\n",
      "           1       0.89      0.06      0.11       908\n",
      "\n",
      "    accuracy                           0.79      4046\n",
      "   macro avg       0.84      0.53      0.49      4046\n",
      "weighted avg       0.81      0.79      0.71      4046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('C:/Users/sarpk/Desktop/TUe courses/Language&AI/assignment/cleaned_extrovert.csv', engine='pyarrow')\n",
    "X = df['post']\n",
    "y = df['label']\n",
    "\n",
    "#split without stratification\n",
    "X_train_nstrat, X_test_nstrat, y_train_nstrat, y_test_nstrat = train_test_split(X, y, test_size=0.1, random_state=5)\n",
    "\n",
    "#split with stratification\n",
    "X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(X, y, test_size=0.1, random_state=5, stratify=y)\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer() #using simple tfidf tokenizer to tokenize the text data\n",
    "\n",
    "X_train_tfidf_nstrat = tfidf_vectorizer.fit_transform(X_train_nstrat) #without strat\n",
    "X_test_tfidf_nstrat = tfidf_vectorizer.transform(X_test_nstrat)\n",
    "\n",
    "X_train_tfidf_strat = tfidf_vectorizer.fit_transform(X_train_strat) #with strat\n",
    "X_test_tfidf_strat = tfidf_vectorizer.transform(X_test_strat)\n",
    "\n",
    "\n",
    "clf_nstrat = MultinomialNB() #using naive bayes as classifier to train. with strat\n",
    "clf_nstrat.fit(X_train_tfidf_nstrat, y_train_nstrat)\n",
    "\n",
    "clf_strat = MultinomialNB() #without strat\n",
    "clf_strat.fit(X_train_tfidf_strat, y_train_strat)\n",
    "\n",
    "\n",
    "y_pred_nstrat = clf_nstrat.predict(X_test_tfidf_nstrat) #prediction and evaluation for both stratified and non stratified\n",
    "print(\"Classification report without stratification:\")\n",
    "print(classification_report(y_test_nstrat, y_pred_nstrat))\n",
    "\n",
    "y_pred_strat = clf_strat.predict(X_test_tfidf_strat)\n",
    "print(\"Classification report with stratification:\")\n",
    "print(classification_report(y_test_strat, y_pred_strat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc024f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report with shuffle:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      6274\n",
      "           1       0.82      0.07      0.13      1817\n",
      "\n",
      "    accuracy                           0.79      8091\n",
      "   macro avg       0.80      0.53      0.51      8091\n",
      "weighted avg       0.79      0.79      0.71      8091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train_shuffle, X_test_shuffle = X[train_index], X[test_index]\n",
    "    y_train_shuffle, y_test_shuffle = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "    \n",
    "tfidf_vectorizer = TfidfVectorizer() #using simple tfidf tokenizer to tokenize the text data\n",
    "\n",
    "X_train_tfidf_shuffle = tfidf_vectorizer.fit_transform(X_train_shuffle) #with shuffle\n",
    "X_test_tfidf_shuffle = tfidf_vectorizer.transform(X_test_shuffle)\n",
    "\n",
    "clf_shuffle = MultinomialNB() #naive bayes as classifier for this too\n",
    "clf_shuffle.fit(X_train_tfidf_shuffle, y_train_shuffle)\n",
    "\n",
    "y_pred_shuffle = clf_shuffle.predict(X_test_tfidf_shuffle) #prediction and evaluation for both stratified and non stratified\n",
    "print(\"Classification report with shuffle:\")\n",
    "print(classification_report(y_test_shuffle, y_pred_shuffle))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd3b4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing out another SMOTE method from the internet -- not that important\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from imblearn import FunctionSampler\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "pipeline = [\n",
    "    make_pipeline(FunctionSampler(), classifier),\n",
    "    make_pipeline(RandomOverSampler(random_state=5), classifier),\n",
    "    make_pipeline(ADASYN(random_state=5), classifier),\n",
    "    make_pipeline(SMOTE(random_state=5), classifier),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eba4d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9501f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc, roc_curve\n",
    "\n",
    "disp = []\n",
    "for model in pipeline:\n",
    "    # compute the mean fpr/tpr to get the mean ROC curve\n",
    "    mean_tpr, mean_fpr = 0.0, np.linspace(0, 1, 100)\n",
    "    for train, test in cv.split(X, y):\n",
    "        model.fit(X[train], y[train])\n",
    "        y_proba = model.predict_proba(X[test])\n",
    "\n",
    "        pos_label_idx = np.flatnonzero(model.classes_ == pos_label)[0]\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "            y[test], y_proba[:, pos_label_idx], pos_label=pos_label\n",
    "        )\n",
    "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "\n",
    "    mean_tpr /= cv.get_n_splits(X, y)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "    # Create a display that we will reuse to make the aggregated plots for\n",
    "    # all methods\n",
    "    disp.append(\n",
    "        RocCurveDisplay(\n",
    "            fpr=mean_fpr,\n",
    "            tpr=mean_tpr,\n",
    "            roc_auc=mean_auc,\n",
    "            estimator_name=f\"{model[0].__class__.__name__}\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afd042fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "data = fetch_lfw_people()\n",
    "george_bush_id = 1871  # Photos of George W. Bush\n",
    "bill_clinton_id = 531  # Photos of Bill Clinton\n",
    "classes = [george_bush_id, bill_clinton_id]\n",
    "classes_name = np.array([\"B. Clinton\", \"G.W. Bush\"], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83d399cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 85.       120.666664 149.33333  ...  18.        22.        27.666666]\n",
      " [136.       139.33333  143.33333  ... 131.33333  117.       115.      ]\n",
      " [ 89.        83.333336  66.       ... 126.       156.33333  173.      ]\n",
      " ...\n",
      " [ 31.        44.333332  82.       ... 228.33333  150.        34.      ]\n",
      " [129.66667  119.666664 100.333336 ...  24.666666  24.666666  25.666666]\n",
      " [188.66667  169.66667  159.66667  ... 142.33333  146.33333  147.33333 ]]\n"
     ]
    }
   ],
   "source": [
    "mask_photos = np.isin(data.target, classes)\n",
    "X, y = data.data[mask_photos], data.target[mask_photos]\n",
    "y = (y == george_bush_id).astype(np.int8)\n",
    "y = classes_name[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5eec83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive label considered as the minority class is B. Clinton\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlkklEQVR4nO3deZCV5Znw4ftAQ7N1o7QLEHBBFIQoKFsALWBARBHNDA5Gp1RMjAuOQkaMEicsiZHBqFETl9LBZUZQo4WjgoNoAMeFaFx6NIK4sAgCIljSKJvC+/3hcD5bGuhmacLDdVWdKvrtd7lPP4X18z3nNLksy7IAAGCvV2NPDwAAwK4h7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIeyAavfWW2/FBRdcEIcffnjUqVMnGjRoEMcff3zccMMN8dlnn+X369mzZ/Ts2XPPDVoFCxYsiFwuF/fff39+2+jRoyOXy1XpPGvWrInRo0fHzJkzq3RcRdc67LDD4rTTTqvSebZn4sSJccstt1T4vVwuF6NHj96l1wOqpmBPDwDsW+65554YMmRItGrVKq666qpo06ZNfPXVV/Haa6/FXXfdFbNmzYrHH398T4+5S1x44YXRr1+/Kh2zZs2aGDNmTERElaJ2R661IyZOnBh//etfY9iwYVt8b9asWdGsWbPdPgOwdcIOqDazZs2KSy+9NE466aT4r//6rygsLMx/76STToorr7wypk6dugcn3LWaNWu220NnzZo1Ua9evWq51vb84Ac/2KPXB7wUC1Sj66+/PnK5XNx9993lom6z2rVrx+mnn77Nc4wZMya6dOkSjRo1iuLi4jj++ONj/PjxkWVZuf2mT58ePXv2jJKSkqhbt24ccsghMXDgwFizZk1+nzvvvDPatWsXDRo0iKKiomjdunX84he/2O7zWLJkSQwaNCiKioqiYcOGcdZZZ8WyZcu22K+il0e3NdeCBQviwAMPzD/PXC4XuVwuBg8eXO58b7zxRpx55pmx//77xxFHHLHVa232+OOPx7HHHht16tSJFi1axG233Vbu+/fff3/kcrlYsGBBue0zZ86MXC6Xf1m4Z8+eMWXKlFi4cGF+tm9fs6KXYv/617/GGWecEfvvv3/UqVMn2rdvHw888ECF13nooYfi2muvjaZNm0ZxcXH06dMn5s6dW+FzAirmjh1QLTZu3BjTp0+PDh06RPPmzXf4PAsWLIiLL744DjnkkIiI+POf/xyXX355fPzxxzFy5Mj8Pv37948TTzwx7r333thvv/3i448/jqlTp8aGDRuiXr168fDDD8eQIUPi8ssvjxtvvDFq1KgRH3zwQcyePXub11+7dm306dMnlixZEmPHjo2jjjoqpkyZEmeddValZt/WXE2aNImpU6dGv3794ic/+UlceOGFERH52NvsH/7hH+JHP/pRXHLJJfHll19u85qlpaUxbNiwGD16dDRu3DgmTJgQQ4cOjQ0bNsTw4cO3O/O33XHHHXHRRRfFhx9+WKmXy+fOnRvdunWLgw46KG677bYoKSmJBx98MAYPHhyffPJJ/PznPy+3/y9+8Yvo3r17/Pu//3uUlZXF1VdfHQMGDIg5c+ZEzZo1qzQr7KuEHVAtVqxYEWvWrInDDz98p85z33335f+8adOm6NmzZ2RZFrfeemv88pe/jFwuF6+//nqsW7cufvvb30a7du3y+59zzjn5P7/00kux3377lbt71bt37+1e/4EHHog5c+bEE088kb+72Ldv31i7dm3cc8892zy2MnN16NAhIr55GXdrL22ef/75+ffhbc+SJUvizTffzF/vlFNOieXLl8evf/3rGDJkSNSrV69S54mIaNOmTey3335RWFhYqZddR48eHRs2bIgZM2bkY/7UU0+Nzz//PMaMGRMXX3xxNGzYsNz5H3zwwfzXNWvWjEGDBsVf/vIXL/NCJXkpFtirTJ8+Pfr06RMNGzaMmjVrRq1atWLkyJGxcuXKWL58eUREtG/fPmrXrh0XXXRRPPDAAzFv3rwtztO5c+f4/PPP4+yzz44nnngiVqxYUanrz5gxI4qKirZ4yfjbcbY1lZmrMgYOHFjpfdu2bVsuIiO+mbWsrCzeeOONHbp+ZU2fPj169+69xR3awYMHx5o1a2LWrFnltn/3Z3rsscdGRMTChQt365yQEmEHVIsDDjgg6tWrF/Pnz9/hc7z66qvRt2/fiPjm07UvvfRS/OUvf4lrr702Ir55mTQi4ogjjojnnnsuDjrooLjsssviiCOOiCOOOCJuvfXW/LnOPffcuPfee2PhwoUxcODAOOigg6JLly7x7LPPbnOGlStXxsEHH7zF9saNG293/srMVRlNmjSp9L4VzbV528qVK6t03apauXJlhbM2bdq0wuuXlJSU+3rz+zA3ryuwfcIOqBY1a9aM3r17x+uvvx6LFy/eoXM8/PDDUatWrZg8eXIMGjQounXrFh07dqxw3xNPPDGeeuqpWLVqVfz5z3+Orl27xrBhw+Lhhx/O73PBBRfEyy+/HKtWrYopU6ZElmVx2mmnbfMOUUlJSXzyySdbbK/owxM7Otf2VOV341U01+Ztm0OqTp06ERGxfv36cvtV9i7m1pSUlMTSpUu32L5kyZKI+Cb2gV1L2AHVZsSIEZFlWfz0pz+NDRs2bPH9r776Kp566qmtHp/L5aKgoKDcG+nXrl0b//mf/7nVY2rWrBldunSJ22+/PSKiwpcf69evH6ecckpce+21sWHDhnjnnXe2er5evXrF6tWr48knnyy3feLEiVs9pipz7eq7VO+880787//+b7ltEydOjKKiojj++OMj4ptfZBzxzS+O/rbvPsfN81V2tt69e8f06dPzIbfZf/zHf0S9evW8bw52Ax+eAKpN165d484774whQ4ZEhw4d4tJLL422bdvGV199FW+++Wbcfffd8f3vfz8GDBhQ4fH9+/ePm2++Oc4555y46KKLYuXKlXHjjTdu8atT7rrrrpg+fXr0798/DjnkkFi3bl3ce++9ERHRp0+fiIj46U9/GnXr1o3u3btHkyZNYtmyZTF27Nho2LBhdOrUaavP4bzzzovf/e53cd5558VvfvObOPLII+Ppp5+OZ555ZrvPvzJzFRUVxaGHHhpPPPFE9O7dOxo1ahQHHHBAPr6qqmnTpnH66afH6NGjo0mTJvHggw/Gs88+G+PGjct/cKJTp07RqlWrGD58eHz99dex//77x+OPPx4vvvjiFuc75phjYtKkSXHnnXdGhw4dokaNGlu9azpq1KiYPHly9OrVK0aOHBmNGjWKCRMmxJQpU+KGG24o98EJYBfJAKpZaWlpdv7552eHHHJIVrt27ax+/frZcccdl40cOTJbvnx5fr8ePXpkPXr0KHfsvffem7Vq1SorLCzMWrRokY0dOzYbP358FhHZ/PnzsyzLslmzZmV///d/nx166KFZYWFhVlJSkvXo0SN78skn8+d54IEHsl69emUHH3xwVrt27axp06bZoEGDsrfeemu78y9evDgbOHBg1qBBg6yoqCgbOHBg9vLLL2cRkd133335/UaNGpV9+z+zlZkry7Lsueeey4477rissLAwi4js/PPPL3e+Tz/9dIuZvnutLMuyQw89NOvfv3/22GOPZW3bts1q166dHXbYYdnNN9+8xfHvvfde1rdv36y4uDg78MADs8svvzybMmVKFhHZjBkz8vt99tln2Zlnnpntt99+WS6XK3fNiMhGjRpV7rxvv/12NmDAgKxhw4ZZ7dq1s3bt2pX7GWVZls2YMSOLiOzRRx8tt33+/Plb/EyBbctl2Xd+qycAAHsl77EDAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhF9QXA02bdoUS5YsiaKioir9U0AAAFmWxerVq6Np06ZRo8a278kJu2qwZMmSaN68+Z4eAwDYiy1atCiaNWu2zX2EXTUoKiqKiG8WpLi4eA9PAwDsTcrKyqJ58+b5ntgWYVcNNr/8WlxcLOwAgB1Smbdz+fAEAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIoQdAEAihB0AQCKEHQBAIgr29AD7ku+PeiZqFNarlmst+Lf+1XIdAOBvhzt2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAInYa8Ju8ODB8cMf/jD/dc+ePWPYsGF7bB4AgL81Oxx2gwcPjlwul3+UlJREv3794q233qryubIsi7vvvju6dOkSDRo0iP322y86duwYt9xyS6xZs6bCYyZNmhS//vWvK32NBQsWRC6Xi9LS0irPBwCwN9ipO3b9+vWLpUuXxtKlS+NPf/pTFBQUxGmnnVbl85x77rkxbNiwOOOMM2LGjBlRWloav/zlL+OJJ56IadOmVXhMo0aNoqioaGfGBwBIyk6FXWFhYTRu3DgaN24c7du3j6uvvjoWLVoUn376aaXP8cc//jEmTJgQDz30UPziF7+ITp06xWGHHRZnnHFGTJ8+PXr16lXhcd99Kfawww6L66+/Pn784x9HUVFRHHLIIXH33Xfnv3/44YdHRMRxxx0XuVwuevbsGRERmzZtil/96lfRrFmzKCwsjPbt28fUqVPzx22+0zdp0qTo1atX1KtXL9q1axezZs2qwk8KAGD322Xvsfviiy9iwoQJ0bJlyygpKan0cRMmTIhWrVrFGWecscX3crlcNGzYsNLnuummm6Jjx47x5ptvxpAhQ+LSSy+Nd999NyIiXn311YiIeO6552Lp0qUxadKkiIi49dZb46abboobb7wx3nrrrTj55JPj9NNPj/fff7/cua+99toYPnx4lJaWxlFHHRVnn312fP3115WeDQBgd9upsJs8eXI0aNAgGjRoEEVFRfHkk0/GI488EjVqVP6077//frRq1Wpnxsg79dRTY8iQIdGyZcu4+uqr44ADDoiZM2dGRMSBBx4YERElJSXRuHHjaNSoUURE3HjjjXH11VfHj370o2jVqlWMGzcu2rdvH7fccku5cw8fPjz69+8fRx11VIwZMyYWLlwYH3zwQYVzrF+/PsrKyso9AAB2t50Ku169ekVpaWmUlpbGK6+8En379o1TTjklFi5cWOlzZFkWuVxuZ8bIO/bYY/N/zuVy0bhx41i+fPlW9y8rK4slS5ZE9+7dy23v3r17zJkzZ6vnbtKkSUTEVs89duzYaNiwYf7RvHnzKj8XAICq2qmwq1+/frRs2TJatmwZnTt3jvHjx8eXX34Z99xzT6XPcdRRR20RUTuqVq1a5b7O5XKxadOm7R733bCsKDa/fe7N39vauUeMGBGrVq3KPxYtWlSp+QEAdsYu/T12uVwuatSoEWvXrq30Meecc06899578cQTT2zxvSzLYtWqVbtkttq1a0dExMaNG/PbiouLo2nTpvHiiy+W2/fll1+Oo48+eoevVVhYGMXFxeUeAAC7206F3fr162PZsmWxbNmymDNnTlx++eXxxRdfxIABA/L79O7dO/7whz9s9RyDBg2Ks846K84+++wYO3ZsvPbaa7Fw4cKYPHly9OnTJ2bMmLEzI+YddNBBUbdu3Zg6dWp88skn+WC86qqrYty4cfHII4/E3Llz45prronS0tIYOnToLrkuAEB1KdiZg6dOnZp/v1lRUVG0bt06Hn300fyvEomI+PDDD2PFihVbPUcul4uJEyfG3XffHffee29cd911UVBQEEceeWScd955cfLJJ+/MiHkFBQVx2223xa9+9asYOXJknHjiiTFz5sy44ooroqysLK688spYvnx5tGnTJp588sk48sgjd8l1AQCqSy7LsmxPD5G6srKybz5EMeyPUaOwXrVcc8G/9a+W6wAAu9fmjli1atV239611/xbsQAAbJuwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEiEsAMASISwAwBIhLADAEhEwZ4eYF/y1zEnR3Fx8Z4eAwBIlDt2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJEHYAAIkQdgAAiRB2AACJKNjTA+xLvj/qmahRWG9PjwEA7EIL/q3/nh4hzx07AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIu+2YOXNm5HK5+Pzzz/f0KAAA21TlsFu2bFkMHTo0WrZsGXXq1ImDDz44TjjhhLjrrrtizZo1FR4zderUyOVysWzZsnLbGzduHM2bNy+3bfHixZHL5WLatGnbnWXw4MGRy+Xyj5KSkujXr1+89dZbVX1aAAB7vSqF3bx58+K4446LadOmxfXXXx9vvvlmPPfcc/Gzn/0snnrqqXjuuecqPO6EE06IgoKCmDlzZn7bnDlzYt26dVFWVhYffPBBfvuMGTOiVq1a0b1790rN1K9fv1i6dGksXbo0/vSnP0VBQUGcdtppVXlaAABJqFLYDRkyJAoKCuK1116LQYMGxdFHHx3HHHNMDBw4MKZMmRIDBgyo8LgGDRpEp06dyoXdzJkz44QTTogTTjhhi+2dO3eO+vXrV2qmwsLCaNy4cTRu3Djat28fV199dSxatCg+/fTT/Pm++1JqaWlp5HK5WLBgQURELFy4MAYMGBD7779/1K9fP9q2bRtPP/10ueu8/vrr0bFjx6hXr15069Yt5s6dW6n5AACqS6XDbuXKlTFt2rS47LLLthpduVxuq8f36tUrZsyYkf96xowZ0bNnz+jRo8cW23v16lXZscr54osvYsKECdGyZcsoKSmp9HGXXXZZrF+/Pv7nf/4n3n777Rg3blw0aNCg3D7XXntt3HTTTfHaa69FQUFB/PjHP96hGQEAdpeCyu74wQcfRJZl0apVq3LbDzjggFi3bl1EfBNI48aNq/D4nj17xvXXXx9Lly6NJk2axPPPPx9XXXVVbNq0KW699daIiFi0aFHMnz+/SmE3efLkfIR9+eWX0aRJk5g8eXLUqFH5m5EfffRRDBw4MI455piIiGjRosUW+/zmN7+JHj16RETENddcE/37949169ZFnTp1tth3/fr1sX79+vzXZWVllZ4FAGBHVfnDE9+9K/fqq69GaWlptG3btlzMfFf37t2jdu3aMXPmzJg9e3asXbs2jj/++OjQoUOUlZXF+++/HzNmzIjCwsLo1q1bpefp1atXlJaWRmlpabzyyivRt2/fOOWUU2LhwoWVPscVV1wR1113XXTv3j1GjRpV4Ycvjj322PyfmzRpEhERy5cvr/B8Y8eOjYYNG+Yf3/2ACADA7lDpsGvZsmXkcrl49913y21v0aJFtGzZMurWrbvN4+vVqxedO3eOGTNmxIwZM+KEE06ImjVrRkFBQXTr1i2/vWvXrhXeBdua+vXrR8uWLaNly5bRuXPnGD9+fHz55Zdxzz33fPME/+/OXZZl+WO++uqrcue48MILY968eXHuuefG22+/HR07dozf//735fapVatW/s+b43bTpk0VzjRixIhYtWpV/rFo0aJKPx8AgB1V6bArKSmJk046Kf7whz/El19+uUMX69WrV8ycOTNmzpwZPXv2zG/v0aNHfvuOvr9us1wuFzVq1Ii1a9dGRMSBBx4YERFLly7N71NaWrrFcc2bN49LLrkkJk2aFFdeeWU+DHdEYWFhFBcXl3sAAOxuVXop9o477oivv/46OnbsGI888kjMmTMn5s6dGw8++GC8++67UbNmzfy+5513XowYMaLc8b169Yr3338/pk6dmn+/WsQ3YTd58uRYsGBBPuxeffXVaN26dXz88cfbnGn9+vWxbNmyWLZsWcyZMycuv/zy+OKLL/Kf0G3ZsmU0b948Ro8eHe+9915MmTIlbrrppnLnGDZsWDzzzDMxf/78eOONN2L69Olx9NFHV+VHAwCwx1X6wxMREUcccUS8+eabcf3118eIESNi8eLFUVhYGG3atInhw4fHkCFD8vt+9NFHW3yAoWvXrlFYWBgRER06dMhv79SpU2zcuDHq1q0bXbp0iYiINWvWxNy5c7d42fS7pk6dmn/PW1FRUbRu3ToeffTR/B3BWrVqxUMPPRSXXnpptGvXLjp16hTXXXdd/OM//mP+HBs3bozLLrssFi9eHMXFxdGvX7/43e9+V5UfDQDAHpfLvv3mM3aLsrKybz5EMeyPUaOw3p4eBwDYhRb8W//dev7NHbFq1artvr3LvxULAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQCGEHAJAIYQcAkAhhBwCQiII9PcC+5K9jTo7i4uI9PQYAkCh37AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABIh7AAAEiHsAAASIewAABJRsKcH2BdkWRYREWVlZXt4EgBgb7O5Hzb3xLYIu2qwcuXKiIho3rz5Hp4EANhbrV69Oho2bLjNfYRdNWjUqFFERHz00UfbXRD2nLKysmjevHksWrQoiouL9/Q4bIO12jtYp72HtfrblmVZrF69Opo2bbrdfYVdNahR45u3MjZs2NBfmL1AcXGxddpLWKu9g3Xae1irv12VvTHkwxMAAIkQdgAAiRB21aCwsDBGjRoVhYWFe3oUtsE67T2s1d7BOu09rFU6clllPjsLAMDfPHfsAAASIewAABIh7AAAEiHsAAASIex2kTvuuCMOP/zwqFOnTnTo0CFeeOGFbe7//PPPR4cOHaJOnTrRokWLuOuuu6pp0n1bVdZp0qRJcdJJJ8WBBx4YxcXF0bVr13jmmWeqcdp9W1X/Tm320ksvRUFBQbRv3373DkhEVH2d1q9fH9dee20ceuihUVhYGEcccUTce++91TTtvq2qazVhwoRo165d1KtXL5o0aRIXXHBB/p/I5G9Yxk57+OGHs1q1amX33HNPNnv27Gzo0KFZ/fr1s4ULF1a4/7x587J69eplQ4cOzWbPnp3dc889Wa1atbLHHnusmifft1R1nYYOHZqNGzcue/XVV7P33nsvGzFiRFarVq3sjTfeqObJ9z1VXavNPv/886xFixZZ3759s3bt2lXPsPuwHVmn008/PevSpUv27LPPZvPnz89eeeWV7KWXXqrGqfdNVV2rF154IatRo0Z26623ZvPmzcteeOGFrG3bttkPf/jDap6cqhJ2u0Dnzp2zSy65pNy21q1bZ9dcc02F+//85z/PWrduXW7bxRdfnP3gBz/YbTNS9XWqSJs2bbIxY8bs6tH4jh1dq7POOiv713/912zUqFHCrhpUdZ3++7//O2vYsGG2cuXK6hiPb6nqWv32t7/NWrRoUW7bbbfdljVr1my3zciu4aXYnbRhw4Z4/fXXo2/fvuW29+3bN15++eUKj5k1a9YW+5988snx2muvxVdffbXbZt2X7cg6fdemTZti9erV0ahRo90xIv9nR9fqvvvuiw8//DBGjRq1u0ckdmydnnzyyejYsWPccMMN8b3vfS+OOuqoGD58eKxdu7Y6Rt5n7chadevWLRYvXhxPP/10ZFkWn3zySTz22GPRv3//6hiZnVCwpwfY261YsSI2btwYBx98cLntBx98cCxbtqzCY5YtW1bh/l9//XWsWLEimjRpstvm3VftyDp910033RRffvllDBo0aHeMyP/ZkbV6//3345prrokXXnghCgr8Z6067Mg6zZs3L1588cWoU6dOPP7447FixYoYMmRIfPbZZ95ntxvtyFp169YtJkyYEGeddVasW7cuvv766zj99NPj97//fXWMzE5wx24XyeVy5b7OsmyLbdvbv6Lt7FpVXafNHnrooRg9enQ88sgjcdBBB+2u8fiWyq7Vxo0b45xzzokxY8bEUUcdVV3j8X+q8ndq06ZNkcvlYsKECdG5c+c49dRT4+abb47777/fXbtqUJW1mj17dlxxxRUxcuTIeP3112Pq1Kkxf/78uOSSS6pjVHaC/7XdSQcccEDUrFlzi//rWb58+Rb/d7RZ48aNK9y/oKAgSkpKdtus+7IdWafNHnnkkfjJT34Sjz76aPTp02d3jklUfa1Wr14dr732Wrz55pvxz//8zxHxTUBkWRYFBQUxbdq0+Lu/+7tqmX1fsiN/p5o0aRLf+973omHDhvltRx99dGRZFosXL44jjzxyt868r9qRtRo7dmx07949rrrqqoiIOPbYY6N+/fpx4oknxnXXXeeVpb9h7tjtpNq1a0eHDh3i2WefLbf92WefjW7dulV4TNeuXbfYf9q0adGxY8eoVavWbpt1X7Yj6xTxzZ26wYMHx8SJE723pJpUda2Ki4vj7bffjtLS0vzjkksuiVatWkVpaWl06dKlukbfp+zI36nu3bvHkiVL4osvvshve++996JGjRrRrFmz3TrvvmxH1mrNmjVRo0b5RKhZs2ZE/P9XmPgbtac+tZGSzR8jHz9+fDZ79uxs2LBhWf369bMFCxZkWZZl11xzTXbuuefm99/8605+9rOfZbNnz87Gjx/v151Ug6qu08SJE7OCgoLs9ttvz5YuXZp/fP7553vqKewzqrpW3+VTsdWjquu0evXqrFmzZtmZZ56ZvfPOO9nzzz+fHXnkkdmFF164p57CPqOqa3XfffdlBQUF2R133JF9+OGH2Ysvvph17Ngx69y58556ClSSsNtFbr/99uzQQw/NateunR1//PHZ888/n//e+eefn/Xo0aPc/jNnzsyOO+64rHbt2tlhhx2W3XnnndU88b6pKuvUo0ePLCK2eJx//vnVP/g+qKp/p75N2FWfqq7TnDlzsj59+mR169bNmjVrlv3Lv/xLtmbNmmqeet9U1bW67bbbsjZt2mR169bNmjRpkv3TP/1Ttnjx4mqemqrKZZl7qgAAKfAeOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgEQIOwCARAg7AIBECDsAgET8PzU5X1xZNKERAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "class_distribution = pd.Series(y).value_counts(normalize=True)\n",
    "ax = class_distribution.plot.barh()\n",
    "ax.set_title(\"Class distribution\")\n",
    "pos_label = class_distribution.idxmin()\n",
    "plt.tight_layout()\n",
    "print(f\"The positive label considered as the minority class is {pos_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc5ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
